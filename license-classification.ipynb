{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport re\nimport nltk\nimport json\nimport matplotlib.pyplot as plt\nimport collections, functools, operator\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.sentiment import SentimentIntensityAnalyzer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEXT CORPUS CREATION\nCOMM_DIRECTORY = '/kaggle/input/licenses/Comm'\nNONCOMM_DIRECTORY = '/kaggle/input/licenses/NonC'\n\nstop_words = set(stopwords.words('english'))\n\ndef tokkenizer(directory):\n    text_corpus = ''\n    for file in os.listdir(directory):\n        with open(os.path.join(directory, file)) as json_file:\n            json_corpus = json.load(json_file)\n            text_corpus += json_corpus['licenseText']\n            text_corpus = re.sub(r\"[\\n,\\-\\=()%\\\\/]\", ' ', text_corpus)\n            text_corpus = re.sub(r\" +\", ' ', text_corpus)\n\n    token_text = word_tokenize(text_corpus)      \n    token_text_stop = [w for w in comm_tokens if not w.lower() in stop_words]\n    return token_text, token_text_stop, text_corpus\n\ncomm_tokens, comm_tokens_stop, comm_corpus = tokkenizer(COMM_DIRECTORY)\nnoncomm_tokens, noncomm_tokens_stop, noncomm_corpus = tokkenizer(NONCOMM_DIRECTORY)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T21:10:08.441859Z","iopub.execute_input":"2023-01-19T21:10:08.442347Z","iopub.status.idle":"2023-01-19T21:10:51.390596Z","shell.execute_reply.started":"2023-01-19T21:10:08.442312Z","shell.execute_reply":"2023-01-19T21:10:51.389339Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"#SENTIMENT ANALYSIS\ndef sentiment_analizer(corpus, text):\n    sia = SentimentIntensityAnalyzer()\n    comercial_corpus_sent = corpus.split('.')\n    scores = list(map(lambda x: sia.polarity_scores(x), comercial_corpus_sent))\n    result = dict(functools.reduce(operator.add, map(collections.Counter, scores)))\n    result = {key: value / len(scores) for key, value in result.items()}\n    print(text)\n    print(result)\n\nsentiment_analizer(comercial_corpus, 'COMMERCIONAL')\nsentiment_analizer(noncomercial_corpus, 'NONCOMMERCIONAL')","metadata":{"execution":{"iopub.status.busy":"2023-01-19T21:10:51.393384Z","iopub.execute_input":"2023-01-19T21:10:51.394318Z","iopub.status.idle":"2023-01-19T21:10:59.698762Z","shell.execute_reply.started":"2023-01-19T21:10:51.394253Z","shell.execute_reply":"2023-01-19T21:10:59.697507Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"COMMERCIONAL\n{'neu': 0.7376922911514888, 'pos': 0.06345812278249664, 'compound': 0.13032507257284062, 'neg': 0.021120309644124344}\nNONCOMMERCIONAL\n{'neu': 0.7052508709067419, 'pos': 0.05898312929232629, 'compound': 0.11334192793868764, 'neg': 0.022417487807305576}\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_word_cloud(text):\n    comm_wordcloud = WordCloud(width = 800, height = 800,\n                    background_color ='white', stopwords={''},\n                    min_font_size = 10).generate(' '.join(text))\n\n    # plot the WordCloud image                      \n    plt.figure(figsize = (8, 8), facecolor = None)\n    plt.imshow(comm_wordcloud)\n    plt.axis(\"off\")\n    plt.tight_layout(pad = 0)\n\n    plt.show()\n\ncreate_word_cloud(comm_tokens)\ncreate_word_cloud(noncomm_tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stop_words_modi = {'the', ',', 'of', '.', '-', 'to', 'this', 'in', 'that', 'a', '(', ')'}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comm_most_common = nltk.FreqDist(w.lower() for w in comm_tokens)\nnoncomm_most_common = nltk.FreqDist(w.lower() for w in noncomm_tokens)\ncomm_top = comm_most_common.most_common(100)\nnoncomm_top = noncomm_most_common.most_common(100)\n\ncomm_only_words = list(map(lambda x: re.sub(\"[0-9(),' \\\"]\",'' ,str(x)), comm_top))\nnoncomm_only_words = list(map(lambda x: re.sub(\"[0-9(),' \\\"]\",'' ,str(x)), noncomm_top))\n\ndiff = list(set(comm_only_words) - set(noncomm_only_words))\ndiff_comparision = [[w, comm_most_common[w], noncomm_most_common[w]] for w in diff]\n\nprint(diff)\nprint()\nprint(diff_comparision)","metadata":{"execution":{"iopub.status.busy":"2023-01-19T21:29:24.317233Z","iopub.execute_input":"2023-01-19T21:29:24.317632Z","iopub.status.idle":"2023-01-19T21:29:24.863437Z","shell.execute_reply.started":"2023-01-19T21:29:24.317601Z","shell.execute_reply":"2023-01-19T21:29:24.862167Z"},"trusted":true},"execution_count":149,"outputs":[{"name":"stdout","text":"['sections', 'following', 'limitation', 'library', 'patent', 'copies', 's', 'do']\n\n[['sections', 291, 556], ['following', 279, 541], ['limitation', 286, 554], ['library', 369, 339], ['patent', 469, 506], ['copies', 322, 575], ['s', 138, 331], ['do', 322, 537]]\n","output_type":"stream"}]}]}